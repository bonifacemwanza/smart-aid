{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Depth Estimation with Depth Anything V2\n",
    "\n",
    "This notebook demonstrates monocular depth estimation using Depth Anything V2.\n",
    "\n",
    "## What You'll Learn\n",
    "- How monocular depth estimation works\n",
    "- Loading and using Depth Anything V2\n",
    "- Visualizing depth maps\n",
    "- Extracting distance information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from src.config import DepthConfig\n",
    "from src.depth import DepthEstimator\n",
    "from src.utils import Timer, create_side_by_side\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Depth Anything V2 Model\n",
    "\n",
    "Available models:\n",
    "- `vits` (Small): 24M params, fastest\n",
    "- `vitb` (Base): 97M params, balanced\n",
    "- `vitl` (Large): 335M params, most accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DepthConfig(\n",
    "    model=\"vits\",  # Use small model for speed\n",
    "    max_distance=10.0,\n",
    "    colormap=\"inferno\"\n",
    ")\n",
    "\n",
    "depth_estimator = DepthEstimator(config)\n",
    "\n",
    "print(\"Loading Depth Anything V2 model...\")\n",
    "print(\"(First load downloads model from HuggingFace)\")\n",
    "start = time.time()\n",
    "if depth_estimator.load():\n",
    "    print(f\"Model loaded in {time.time()-start:.2f}s\")\n",
    "else:\n",
    "    print(\"Failed to load model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captures_dir = Path(\"../data/captures\")\n",
    "samples_dir = Path(\"../data/sample_images\")\n",
    "results_dir = Path(\"../data/results\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "image_files = list(captures_dir.glob(\"*.jpg\")) + list(samples_dir.glob(\"*.jpg\"))\n",
    "\n",
    "if not image_files:\n",
    "    print(\"No images found. Creating test image with depth variation...\")\n",
    "    test_img = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(6):\n",
    "        x = 50 + i * 100\n",
    "        color = int(255 - i * 40)\n",
    "        cv2.rectangle(test_img, (x, 100), (x+80, 380), (color, color, color), -1)\n",
    "    \n",
    "    samples_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(samples_dir / \"depth_test.jpg\"), test_img)\n",
    "    image_files = [samples_dir / \"depth_test.jpg\"]\n",
    "\n",
    "print(f\"Found {len(image_files)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Depth Estimation on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = image_files[0]\n",
    "print(f\"Processing: {test_image_path.name}\")\n",
    "\n",
    "frame = cv2.imread(str(test_image_path))\n",
    "print(f\"Image shape: {frame.shape}\")\n",
    "\n",
    "timer = Timer(\"depth\")\n",
    "timer.start()\n",
    "depth_map = depth_estimator.estimate(frame)\n",
    "inference_time = timer.stop()\n",
    "\n",
    "print(f\"\\nInference time: {inference_time*1000:.1f}ms\")\n",
    "print(f\"Depth map shape: {depth_map.shape}\")\n",
    "print(f\"Depth range: [{depth_map.min():.3f}, {depth_map.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_colored = depth_estimator.colorize(depth_map)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "im = axes[1].imshow(depth_map, cmap='inferno')\n",
    "axes[1].set_title(\"Depth Map (Raw)\")\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(depth_colored, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(\"Depth Map (Colored)\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / f\"depth_{test_image_path.stem}.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormaps = ['inferno', 'jet', 'viridis', 'plasma', 'magma', 'turbo']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, cmap in zip(axes, colormaps):\n",
    "    colored = depth_estimator.colorize(depth_map, cmap)\n",
    "    ax.imshow(cv2.cvtColor(colored, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_title(f\"Colormap: {cmap}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / \"depth_colormaps.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Distance at Specific Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = frame.shape[:2]\n",
    "points = [\n",
    "    (w//4, h//2, \"Left\"),\n",
    "    (w//2, h//2, \"Center\"),\n",
    "    (3*w//4, h//2, \"Right\"),\n",
    "    (w//2, h//4, \"Top\"),\n",
    "    (w//2, 3*h//4, \"Bottom\"),\n",
    "]\n",
    "\n",
    "print(\"Estimated distances at various points:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "vis_frame = frame.copy()\n",
    "\n",
    "for x, y, name in points:\n",
    "    distance = depth_estimator.get_distance_at(depth_map, x, y)\n",
    "    print(f\"  {name:8s} ({x:3d}, {y:3d}): {distance:.2f}m\")\n",
    "    \n",
    "    cv2.circle(vis_frame, (x, y), 10, (0, 255, 0), -1)\n",
    "    cv2.putText(vis_frame, f\"{distance:.1f}m\", (x+15, y+5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Distance Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = create_side_by_side(vis_frame, depth_colored, \n",
    "                                (\"Distance Points\", \"Depth Map\"))\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.imshow(cv2.cvtColor(combined, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Distance Estimation Results\")\n",
    "plt.axis('off')\n",
    "plt.savefig(results_dir / \"depth_with_distances.jpg\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "total_time = 0\n",
    "\n",
    "for img_path in image_files:\n",
    "    frame = cv2.imread(str(img_path))\n",
    "    if frame is None:\n",
    "        continue\n",
    "    \n",
    "    timer = Timer()\n",
    "    timer.start()\n",
    "    depth_map = depth_estimator.estimate(frame)\n",
    "    elapsed = timer.stop()\n",
    "    total_time += elapsed\n",
    "    \n",
    "    if depth_map is not None:\n",
    "        all_results.append({\n",
    "            'filename': img_path.name,\n",
    "            'depth_map': depth_map,\n",
    "            'time_ms': elapsed * 1000,\n",
    "            'frame': frame\n",
    "        })\n",
    "\n",
    "print(f\"Processed {len(all_results)} images\")\n",
    "print(f\"Total time: {total_time:.2f}s\")\n",
    "print(f\"Average time: {total_time/len(all_results)*1000:.1f}ms per image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save All Depth Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in all_results:\n",
    "    frame = result['frame']\n",
    "    depth_map = result['depth_map']\n",
    "    filename = result['filename']\n",
    "    \n",
    "    depth_colored = depth_estimator.colorize(depth_map)\n",
    "    combined = create_side_by_side(frame, depth_colored, (\"Original\", \"Depth\"))\n",
    "    \n",
    "    output_path = results_dir / f\"depth_{Path(filename).stem}.jpg\"\n",
    "    cv2.imwrite(str(output_path), combined)\n",
    "\n",
    "print(f\"Saved {len(all_results)} depth results to {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Depth Anything V2\n",
    "\n",
    "### How It Works\n",
    "1. **Monocular Depth**: Estimates depth from a SINGLE RGB image\n",
    "2. **Relative Depth**: Output is normalized [0, 1], not absolute meters\n",
    "3. **Deep Learning**: Uses Vision Transformer (ViT) backbone\n",
    "\n",
    "### Key Points\n",
    "- **Brighter = Closer** in the depth map\n",
    "- **Darker = Farther** in the depth map\n",
    "- Distance is estimated, not measured (no depth sensor)\n",
    "- Works best with good lighting and contrast\n",
    "\n",
    "### For Smart Aid\n",
    "- Combined with object detection â†’ know WHAT is nearby\n",
    "- No extra hardware needed (vs stereo cameras, LiDAR)\n",
    "- Good enough for obstacle avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading Depth Anything V2 model\n",
    "2. Running monocular depth estimation\n",
    "3. Visualizing depth maps with various colormaps\n",
    "4. Extracting estimated distances\n",
    "\n",
    "**Key Metrics:**\n",
    "- Model: Depth Anything V2 Small (24M params)\n",
    "- Inference time: ~60-100ms on MacBook\n",
    "- Output: Relative depth map [0, 1]\n",
    "\n",
    "**Next:** Run notebook 04_fusion_pipeline.ipynb to combine detection + depth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
